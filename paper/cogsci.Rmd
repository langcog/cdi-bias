---
title: "Words aren't created equal: Investigating bias on the CDI"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large \bf Morton Ann Gernsbacher (MAG@Macc.Wisc.Edu)} \\ Department of Psychology, 1202 W. Johnson Street \\ Madison, WI 53706 USA
    \AND {\large \bf Sharon J.~Derry (SDJ@Macc.Wisc.Edu)} \\ Department of Educational Psychology, 1025 W. Johnson Street \\ Madison, WI 53706 USA}

abstract: >
    Children's early language skill has been linked to later educational outcomes, making
    it important to accurately measure early language. Parent-reported instruments such as the 
    Communicative Development Inventories (CDIs) have been shown to provide valid, consistent 
    measures of children's aggregate early language skill. However, CDIs are predominantly 
    comprised of hundreds of vocabulary items, some of which may not be heard (and thus learned) 
    equally often by children of varying backgrounds. Here, we use a database of American English 
    CDIs to identify words that show strong bias for particular groups of children, along the axes
    of sex (male vs. female), race/ethnicity (white vs. non-white), and socioeconomic status 
    (high vs. low). For each axis, we identify dozens of strongly biased items, and show that 
    eliminating these items reduces the expected ability difference between groups. For sex, we
    consider how to propose replacement words that may show less bias, on the basis of their 
    relatively equal frequency in adult speech directed to male and female children.
    
keywords: >
    language acquisition; word learning; measuring instrument bias; development;
    
output: cogsci2016::cogsci_paper
#final-submission: \cogscifinalcopy
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, 
                      message=F, sanitize = T)
```

```{r, libraries}
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(tidyverse)
library(here)

```

# Introduction 

Researchers, clinicians, and parents have long been fascinated with the surprising speed and variability in the growth of young children's vocabulary.
Children's early vocabulary growth is assumed to reflect not only their exposure to child-directed speech, but also the varying difficulty of different types of words, and individual differences in the aptitude of the child -- including potential language deficits.
Research has uncovered both within-child consistency in development, as well as significant influence from external factors.
For example, @bornstein2016stability found stability in core language skills across 10 years of children's development, despite changes in maternal income and education over the study period.
Yet socioeconomic status (SES) has also been found to be predictive of children's early language skill, and of later educational outcomes [for a review, see @schwab2016].
Biological factors are also predictive of language skill: first-born children tend to outpace their siblings, and female children tend to have better language skills than their age-matched male counterparts [@fenson1994] -- an sex-based verbal advantage that continues through high school [see @petersen2018gender for a review].
However, it is also difficult to measure language skill: in any short recording children are unlikely to use all of the words and constructions that they know, and any comprehensive battery of language measures will likely exhaust children's attention span.

The MacArthur-Bates Communicative Development Inventories [CDIs; @Fenson2007] are a set of parent-reported measures of children's productive and receptive language skills, which produce a low-cost and reliable way to estimate children's early language skills [@fenson1994].
CDIs have shown good predictive validity [e.g., @fenson1994; Bornstein et al. 2012, Duff et al. 2015].
Our focus will be on the vocabulary checklist portion of the CDI Words & Sentences (CDI:WS) form, comprised of 680 early-learned words across 22 categories (e.g., animals, vehicles, action words, pronouns) selected to assess the productive vocabulary of children 16 to 30 months of age.
For each item on the CDI:WS, caregivers are asked to respond whether the target child has been heard to say (i.e. produce) the given item.[^1]
Children's total vocabulary score on the CDI:WS is tightly correlated with other facets of early language (e.g., grammatical competence and gesture), suggesting that the language system is "tightly woven" [@frank2021].
Due to these desirable properties, CDIs have been adapted to dozens of languages, and a central repository of CDI data contributed from all over the world has been created [Wordbank; @frank2017; @frank2021].

[^1]: The CDI: Words and Gestures form includes a subset of the CDI:WS items and targets children 12 to 18 months of age, measuring both comprehension and production.

Inspired by the utility and widespread use of the CDI, researchers have recently been using psychometric models on CDI data to construct short, adaptive tests to reliably assess language ability using only a small subset of the CDI items [e.g., @mayor2019, @kachergis2021cat].
These psychometric models typically come from the Item-Response Theory (IRT) framework [@Baker2001], which assumes that not only test-takers (here, children) have normally-distributed ability, but that items (words on the CDI) have normally-distributed difficulty.
The very efficacy of these IRT-based models depends on words varying in difficulty, and hence being more/less informative of the ability level of different individuals.
For example, asking whether a 22-month-old produces the word "ball" is far less informative of that child's language ability than asking whether they produce "table", as 96% of 22-month-olds can produce the former, while only 47% produce the latter.

While it is quite reasonable to expect that some CDI words are easier than others, and even to use these varying difficulties to predict variation in children's language ability, the use of psychometric models highlights the possibility that some CDI items may function differently (i.e., be more/less difficult) for different groups of children.
The idea that some items on a test may show bias, favoring one group over another, is known as Differential Item Function (DIF; @holland1993differential]. 
A variety of 


## Fundamental DIF Problem


what is our goal for measuring vocabulary? - identifying language delays, predicting later reading, or talking...

how you select items influences how well you achieve these goals (and what bias you find)

We take the approach put forward by @stenhaug2021treading: GLIMMER plots based on the 1-parameter logistic are sufficient to identify bias, without potentially obscuring DIF in a more complex model's additional parameters.

Differential item functioning (DIF) is a technique in IRT used to identify items that show bias against demographic groups. 
DIF is a statistical characteristic of an item that shows the extent to which the item might operate differently or measure varying abilities for subgroups and members of separate demographic groups. 
DIF is, however, a challenging metric for identifying bias for a couple reasons. 
Firstly, DIF is extremely hard to accurately root out. 
The process of finding DIF involves using the test you used to do IRT analysis in order to look for bias within the very same test. 
Secondly, the presence of DIF does not necessarily indicate the presence of bias; it can indicate that one demographic has a higher average ability level than the other. 
These two issues are the basis upon which we get the Fundamental DIF Identification problem. 

This problem can be be understood through a concrete example that is well-known from research on early language learning: consider the fact that females show a larger vocabulary than males across early development [see @frank2021 Ch. 6?; OTHER REFS]. 
The question is whether or not females actually have a higher ability level, or if the tests predominantly have words that are easier for females (i.e., biased).
(It could even be that the test is biased toward males but the language ability of females is large enough to overcome that bias.)
To address this question, we need to know the ability levels of girls and boys in order to confirm that if a word is learned earlier by girls it is simply because of an ability difference rather than a bias inherent to the word. The problem arises from the fact that we measure ability level using the very same test that we are trying to check for biased words. 
If the boys and girls were of the same average language ability, this would not be an issue but given the evidence showing that girls have a higher ability level, we need to know the difference in ability so that when we find DIF for a specific word can be sure it is outside of the expecting DIF that results naturally from their difference in ability.

The outline of this paper is as follows.
First, we will introduce the Wordbank data and the Rasch model we use to analyze the data.

# Methods

## Vocabulary Data

```{r import-data}
load(here("data/en_ws_production.Rdata")) # d_demo, d_mat, en_wg (items)

#Add this exclusion to the Analysis 
removed <- d_demo %>%
  filter(comprehension!=0)
#this is the actually d_demo we used so we must use this in our report
d_demo <- d_demo %>% 
  #filter(comprehension!=0, !is.na(sex)) %>% # can't fit children not producing words, or with NA sex in group model
  arrange(data_id) %>%
  mutate(eth_group = ifelse(ethnicity=="White", "White", "Nonwhite"),
         ses_group = 
           ifelse(is.element(mom_ed, c("None", "Primary", "Some Secondary", "Secondary")), "low", "high"))
```

### Participants

```{r, echo=F}
sex_tab <- table(d_demo$sex)
ses_tab <- table(d_demo$ses_group)
eth_tab <- table(d_demo$ethnicity)
eth2_tab <- table(d_demo$eth_group)
```


We analyze parent-reported Wordbank data from `r nrow(d_demo)` American English CDI: Words & Sentences administrations for children `r min(d_demo$age)` to `r max(d_demo$age)` months of age [@frank2017; @frank2021].
Unlike other projects Wordbank relies on the kindness of others to contribute their data which means that often meta-data for some sets is missing. 
When they received complete information, the Wordbank data set collected demographic data consisting of Birth Order, Race/Ethnicity, Sex and Mothers Education. 
We focused on comparing data between demographic groups on the axes of Sex, Ethnicity and Mother's Education, a proxy for socioeconomic status (henceforth, SES). 
Our data included `r sex_tab["Female"]` female and `r sex_tab["Male"]` male participants, and an additional `r sum(is.na(d_demo$sex))` participants whose sex remained unreported. 
In terms of Ethnicity data was recorded from `r eth_tab["White"]` white, `r eth_tab["Asian"]` Asian, `r eth_tab["Black"]` Black, `r eth_tab["Hispanic"]` Hispanic, and `r eth_tab["Other"]` “Other” participants as well as `r sum(is.na(d_demo$ethnicity))` unreported. Given our distribution of ethnicities, for our analysis we split participants into White (`r eth2_tab["White"]`) and Non-White (`r eth2_tab["Nonwhite"]`). 
Finally, we split participants into high and low SES, of which we had `r ses_tab["high"]` high SES participants, corresponding to mothers' education of some college or higher and `r ses_tab["low"]` Low SES participants. 
<!-- same for eth, SES -->


## Rasch Model

The Rasch model, also known as the 1-parameter logistic (1PL) model, is the simplest Item Response Theory model, and is thus the easiest to use to investigate potential differences in item function across different groups of participants.
The goal of the Rasch model is to jointly estimate for each child $j$ a latent ability $\theta_j$, and for each item $i$ a difficulty parameter $b_i$.
In the model, the probability of child $j$ knowing (i.e., producing or understanding) a given item $i$ is 

$$P_{i}(x_i = 1 | b_{i},\theta_j ) = \frac{1}{1 + e^{-D(\theta_j - b_i )}}$$

where $D$ is a constant scaling parameter ($D=1.702$) which makes the logistic closely match the ogive function in traditional factor analysis [@R-mirt; @reckase2009].
Child ability ($\theta$) and item difficulty ($b$) distributions are standardized (i.e., mean of 0), and expected to be normally-distributed. 
Children with high latent ability ($\theta$) will be more likely to produce any given item than children with lower latent ability, and more difficult items will be produced by fewer children (at any given $\theta$) than easier items.

For each demographic dimension (sex, socioeconomic status, and ethnicity) we fit a separate Rasch model for each demographic group.


# Results

<!-- put the GLIMMERs side-by-side?
```{r 2-col-image, fig.env = "figure*", fig.pos = "h", fig.width=4, fig.height=2, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "This image spans both columns. And the caption text is limited to 0.8 of the width of the document."}

```
-->

```{r sex-glimmer, out.width="\\linewidth", fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.2, fig.height=3.5, set.cap.width=T, num.cols.cap=1, fig.cap = "GLIMMER plot of a sample of CDI:WS words from the sex bias model. Words at the top are easier to learn for females, while those at the bottom are easier for males."}
#img <- png::readPNG("figs/lab_logo_stanford.png")
#grid::grid.raster(img)
knitr::include_graphics("figs/smGLIMMER_sex_prodWS.pdf")
```


```{r ses-glimmer, out.width="\\linewidth", fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3, fig.height=3.5, set.cap.width=T, num.cols.cap=1, fig.cap = "GLIMMER plot of a sample of CDI:WS words from the SES bias model. Words at the top are easier to learn for children from low-SES families, while those at the bottom are easier for those from high-SES families."}
knitr::include_graphics("figs/smGLIMMER_ses_prodWS.pdf")
```


```{r eth-glimmer, out.width="\\linewidth", fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3, fig.height=3.5, set.cap.width=T, num.cols.cap=1, fig.cap = "GLIMMER plot of a sample of CDI:WS words from the ethnicity bias model. Words at the top are easier to learn for children from low-SES families, while those at the bottom are easier for those from high-SES families."}
knitr::include_graphics("figs/smGLIMMER_eth_prodWS.pdf")
```


# Discussion



# Acknowledgements

Place acknowledgments (including funding information) in a section at
the end of the paper.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent

